{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/benayas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import functions as func\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "cut_off_date = '2016-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copiar datos desde GS\n",
    "Ejecutar esta parte en local desde la carpeta en la que esta \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89975,
     "status": "ok",
     "timestamp": 1572870549800,
     "user": {
      "displayName": "Alberto Jose Benayas Alamos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDCSj3xohobtiMw9pws8DJfa69Dtcojufcb0jCImg=s64",
      "userId": "11113370724671368984"
     },
     "user_tz": -60
    },
    "id": "ehvNjxHrYcph",
    "outputId": "71800ecb-5bd3-49d5-e63b-e98b4cd0e7f5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27449,
     "status": "ok",
     "timestamp": 1572870592951,
     "user": {
      "displayName": "Alberto Jose Benayas Alamos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDCSj3xohobtiMw9pws8DJfa69Dtcojufcb0jCImg=s64",
      "userId": "11113370724671368984"
     },
     "user_tz": -60
    },
    "id": "eAZ3ITCy9CkF",
    "outputId": "0cbf55bb-5f27-43fc-d0f0-e8a257bde7d8"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "project_id = 'clean-composite-253713'\n",
    "!gcloud config set project {project_id}\n",
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17276,
     "status": "ok",
     "timestamp": 1572870845906,
     "user": {
      "displayName": "Alberto Jose Benayas Alamos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDCSj3xohobtiMw9pws8DJfa69Dtcojufcb0jCImg=s64",
      "userId": "11113370724671368984"
     },
     "user_tz": -60
    },
    "id": "LedBIKNk9kVY",
    "outputId": "0142d29d-019e-4d8a-9b85-ee37df18ad0a"
   },
   "outputs": [],
   "source": [
    "bucket_name = 'tfmuah2019/data/20191026_080650_W100_A30_O20_S2.0/images/part-0003*'\n",
    "dest = '/content/drive/My Drive/Colab Notebooks/data'\n",
    "\n",
    "!gsutil -m cp -r  gs://{bucket_name} '/content/drive/My Drive/Colab Notebooks/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copiar datos desde CSV a Feather\n",
    "Ejecutar esta parte en local desde la carpeta en la que esta \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/home/benayas/datasets/raw/*')\n",
    "j = 0\n",
    "start = 3\n",
    "grouping = 3\n",
    "for i in tqdm(range(start, len(files), grouping)):\n",
    "    df = func.toDF_all(files[j:i], reb=False)\n",
    "    j = i\n",
    "    df.reset_index(drop=True).to_feather('/home/benayas/datasets/standard/file_' + str(i) + ('.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files = glob.glob('/home/benayas/datasets/standard/*')\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 0 if x == -1 else x )\n",
    "    df_test = df[df['DATE']>=cut_off_date]\n",
    "    df = df[df['DATE']<cut_off_date]\n",
    "    df = func.rebalance(df)\n",
    "    df_train, df_validation = train_test_split(df, shuffle=True, stratify=df[['LABEL']], test_size=0.1)\n",
    "    df_train.reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_up/train/file_' + str(i) + ('.feather'))\n",
    "    df_validation.reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_up/validation/file_' + str(i) + ('.feather'))\n",
    "    func.rebalance(df_test).reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_up/test/file_' + str(i) + ('.feather'))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [16:57<00:00, 53.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files = glob.glob('/home/benayas/datasets/standard/*')\n",
    "#i=0\n",
    "#for f in tqdm(files):\n",
    "    \n",
    "j = 0\n",
    "start = 3\n",
    "grouping = 3\n",
    "for i in tqdm(range(start, len(files), grouping)):\n",
    "    #df = func.toDF(f)\n",
    "    df = func.toDF_all(files[j:i], reb=False)\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0 )\n",
    "    df_test = df[df['DATE']>=cut_off_date]\n",
    "    df = df[df['DATE']<cut_off_date]\n",
    "    #df = func.rebalance(df)\n",
    "    df_train, df_validation = train_test_split(df, shuffle=True, stratify=df[['LABEL']], test_size=0.1)\n",
    "    func.rebalance(df_train).reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_down/train/file_' + str(i) + ('.feather'))\n",
    "    func.rebalance(df_validation).reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_down/validation/file_' + str(i) + ('.feather'))\n",
    "    df_train.reset_index(drop=True).to_feather('/home/benayas/datasets/full_down/train/file_' + str(i) + ('.feather'))\n",
    "    df_validation.reset_index(drop=True).to_feather('/home/benayas/datasets/full_down/validation/file_' + str(i) + ('.feather'))\n",
    "    df_test.reset_index(drop=True).to_feather('/home/benayas/datasets/full_down/test/file_' + str(i) + ('.feather'))\n",
    "    j = i\n",
    "    #i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [03:46<00:00, 11.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files = glob.glob('/home/benayas/datasets/standard/*')\n",
    "df_test_final = pd.DataFrame()\n",
    "\n",
    "j = 0\n",
    "start = 3\n",
    "grouping = 3\n",
    "for i in tqdm(range(start, len(files), grouping)):\n",
    "    df = func.toDF_all(files[j:i], reb=False)\n",
    "    j = i\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0)\n",
    "    df = df[df['DATE']>=cut_off_date]\n",
    "    df_test_final = pd.concat([df_test_final,func.rebalance(df).reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "df_test_final.reset_index(drop=True).to_feather('/home/benayas/datasets/balanced_down/test/file_0' + ('.feather'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = func.toDF('/home/benayas/datasets/balanced_up/test/file_9999' + ('.feather'))\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Test balanceado cantidad de 1:{0}'.format(str(len(df_test[df_test['LABEL']==1]))) )\n",
    "print('Dataset Test balanceado cantidad de 0:{0}'.format(str(len(df_test[df_test['LABEL']==0]))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKabrcrNYcpz"
   },
   "source": [
    "# Modificar Convertir Datos a Feather (train, validation, test)\n",
    "Ejecutar esta parte en local desde la carpeta en la que esta \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2aPLaM6-Ycp5",
    "outputId": "a5ea0423-87d4-4ce2-b12d-775b8a63de6b"
   },
   "outputs": [],
   "source": [
    "import functions as func\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQWn6H6WYcp_",
    "outputId": "a53b6026-b7e2-4101-de88-8d2507bfdc52"
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/home/benayas/datasets/raw*')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIfH-YDBYcqD",
    "outputId": "c5f8a0f2-d887-4214-d08c-dcc8d49d417f"
   },
   "outputs": [],
   "source": [
    "datasets.copy_feather(files, grouping=3, reb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKabrcrNYcpz"
   },
   "source": [
    "# Rebalancear Dataset\n",
    "Ejecutar esta parte en local desde la carpeta en la que esta \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "suffix='simple_down'\n",
    "path = '/home/benayas/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(path + 'train_simple/*')\n",
    "len(files)\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0)\n",
    "    df = func.rebalance(df)\n",
    "    df.reset_index(drop=True).to_feather(path +'train_' + suffix + '/file_' + str(i) + ('.feather'))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(path + 'test_simple/*')\n",
    "len(files)\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0)\n",
    "    df = func.rebalance(df)\n",
    "    df.reset_index(drop=True).to_feather(path +'test_' + suffix + '/file_' + str(i) + ('.feather'))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(path + 'validation_simple/*')\n",
    "len(files)\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0)\n",
    "    df = func.rebalance(df)\n",
    "    df.reset_index(drop=True).to_feather(path + 'validation_' + suffix + '/file_' + str(i) + ('.feather'))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Ejecutar esta parte en local desde la carpeta en la que esta \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativo(x):\n",
    "    return 255-x\n",
    "\n",
    "from random import randint\n",
    "r = randint(0, 256)\n",
    "def alteracion_random(x):\n",
    "    (x+r)%255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time \n",
    "suffix='simple_aug_up'\n",
    "path = '/home/benayas/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = alteracion_random\n",
    "files = glob.glob(path + 'simple_up/train/*')\n",
    "len(files)\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df.iloc[:,21:] = df.iloc[:,21:].apply(f, axis=0)\n",
    "    df.to_feather(path + suffix + '/train' + '/file_aug' + str(int(time.time())) + ('.feather'))\n",
    "    i=i+1\n",
    "\n",
    "files = glob.glob(path + 'simple_up/validation/*')\n",
    "len(files)\n",
    "i=0\n",
    "for f in tqdm(files):\n",
    "    df = func.toDF(f)\n",
    "    df.iloc[:,21:] = df.iloc[:,21:].apply(f, axis=0)\n",
    "    df.to_feather(path + suffix + '/validation' + '/file_aug' + str(int(time.time())) + ('.feather'))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/benayas/datasets/lstm/price_label.csv'\n",
    "df = func.toDF(path)\n",
    "df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == -1 else 0)\n",
    "df_test = df[df['DATE']>=cut_off_date]\n",
    "df_train = df[df['DATE']<cut_off_date]\n",
    "df_test.reset_index(drop=True).to_feather('/home/benayas/datasets/lstm/train/test' + '.feather')\n",
    "df_train.reset_index(drop=True).to_feather('/home/benayas/datasets/lstm/test/train' + '.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy from GS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
